# STORY 01 웹 서버의 설치 장소

## 1. 사내에 웹 서버를 설치하는 경우

- 인터넷을 통해 들어온 패킷이 서버에 도착할 때, 서버의 설치 방식에 따라 도착하는 과정이 다르다.
- 1) 라우터에서 직접 연결하는 경우
    - 패킷은 가장 가까운 POP 에 있는 라우터, 액세스 회선, 서버측 라우터를 경유하여 서버에 도착한다.
    - IP 주소의 부족 및 보안상의 이유로 현재는 주로 사용하는 방법이 아니다.
- 2) 방화벽으로 분리하는 경우
    - 특정 서버의 특정 애플리케이션의 액세스만 허용하고 그 외의 패킷은 차단한다.

## 2. 데이터센터에 웹 서버를 설치하는 경우

- 회사 안에 설치하는 것 외에 데이터 센터의 웹 서버를 사용할 수도 있다.
    - 데이터센터 시설에 서버를 설치하거나 프로바이더가 소유하는 서버를 대여할 수 있다.
- 데이터센터는 프로바이더의 중심 부분에 있는 NOC 에 직접 연결되거나 IX 에 직결되어 고속으로 액세스할 수 있다.
- 어느 경우든지 패킷이 라우터에서 중계되고 서버에 도착한다는 점은 동일하다.

# STORY 02 방화벽의 원리와 동작

## 1. 패킷 필터링형이 주류이다

- 서버의 설치 장소와 관계 없이 방화벽을 설정하는 것이 기본이다.
- 방화벽을 구현하기 위해서 다양한 방법이 있지만 최근에는 패킷 필터링형이 가장 많이 사용된다.
- 특정 서버의 특정 애플리케이션만 허용한다.

## 2. 패킷 필터링의 조건 설정 개념

![](김유빈/1.jpeg)

- 패킷의 헤더에 있는 제어 정보를 보고 판단한다.
- 예를 들어, 인터넷에서 웹 서버로의 접속은 허용하되, 그 반대의 경우는 허용하지 않는다고 가정해보자.
- 가장 먼저 수신처의 IP 주소를 보고 통과하도록 설정되어 있으면 접속을 허용한다. (1행)

## 3. 애플리케이션을 한정할 때 포트 번호를 사용한다

- 웹 서버의 기본 포트는 80번 이므로 수신처 포트가 80번인 패킷은 허용하도록 설정되어 있다.

## 4. 컨트롤 비트로 접속 방향을 판단한다

- 웹의 대부분의 동작은 TCP 프로토콜을 사용하며, 이는 양방향 통신의 특징을 가진다.
- 즉, 한 방향의 통신을 제어하면 이후의 요청이 연결되지 않아 통신을 할 수 없게 된다.
- TCP 는 접속 단계의 동작에서 3개의 패킷이 흐르는데, 최초의 패킷의 경우 SYN 는 1, ACK 는 0 이다.
- 웹 서버에서 인터넷으로의 통신을 차단하고 싶을 경우 최초 패킷을 차단하여 앞으로의 통신을 제어할 수 있다. (2행)
- 인터넷에서 웹 서버로 들어오는 최초의 패킷의 경우 TCP 컨트롤 비트에 대한 조건이 없고, 해당 설정이 통과로 되어 있으므로 통신이 가능하다. (1행)
- IP 및 포트번호, TCP 컨트롤 비트 조건 외에도 다양한 헤더 정보를 이용하여 차단을 설정할 수 있다.
- 다만, UDP 의 경우 TCP 접속 단계가 없으므로 컨트롤 비트를 이용하여 액세스 방향을 판별할 수 없다.

## 5. 사내 LAN 에서 공개 서버용 LAN 으로 조건을 설정한다

- 사내 LAN 과 공개 서버용 LAN 에서의 통신을 위해서 관련 조건을 추가해야 한다.
- 다만, 사내용 LAN 과의 편리한 통신을 위해 공개 서버용 LAN 에 들어온 요청을 모두 허용하도록 설정하면 인터넷의 패킷을 모두 허용하게 되므로 주의해야 한다.

## 6. 밖에서 사내 LAN 으로 액세스 할 수 없다

- 패킷 필터링형 방화벽은 패킷 차단 기능뿐만 아니라 주소 변환 기능도 가지고 있다.
- 사내 LAN 과 인터넷 사이의 설정 시 패킷 차단 설정을 포함하여 주소 변환 기능도 설정해야 한다.

## 7. 방화벽을 통과한다

- 패킷 조건이 ‘차단’ 일 경우 패킷을 폐기하고 이를 기록한다.
- 패킷 조건이 ‘통과’ 일 경우 패킷을 중계하는데, 이는 라우터와 동일하다.

## 8. 방화벽으로 막을 수 없는 공격

- 방화벽은 패킷 흐름의 시점과 종점만을 보고 판단하므로 패킷 데이터에 문제가 있을 경우 차단하지 못한다.

# STORY 03 복수 서버에 리퀘스트를 분배한 서버의 부하 분산

## 1. 처리 능력이 부족하면 복수 서버로 부하 분산된다

- 서버에 액세스가 증가할 경우 분산 처리를 통해 서버의 처리량을 줄일 수 있다.
    - 복수의 서버를 사용하여 처리를 분담하는 방법이다.
- DNS 서버에 하나의 도메인에 복수의 IP 를 등록해놓으면 간단하게 분산 처리를 할 수 있다. (RR)
- 단, DNS 서버는 웹서버의 상황을 모르기 때문에 웹서버에서 문제가 있을 경우에도 요청을 보낼 수 있다.

## 2. 부하 분산 장치를 이용해 복수의 웹 서버로 분할된다

- 웹서버의 상태를 파악하여 효율적으로 처리하기 위해 DNS 서버가 아닌 부하 분산 장치 또는 로드 밸런서가 고안되었다.
- DNS 서버에는 부하 분산 장치를 등록하고, 부하 분산 장치로 요청이 들어오면 여러 웹서버 사이의 요청을 조정한다.
    - 웹 서버와 정기적으로 정보를 교환하여 CPU 나 메모리의 사용률을 수집하고 웹 서버의 부하가 낮은 곳으로 요청할 수 있다.
    - 테스트 패킷을 요청보내 응답 시간을 기준으로 부하를 판단하기도 한다.
    - 테스트가 잦아질 경우 테스트 자체가 부하가 될 수 있기 때문에 웹 서버의 사양에 따라 요청 비율을 미리 설정해둘 수도 있다.
- 이전의 요청을 이어서 처리해야 하는 경우 이전에 요청했던 서버의 정보가 필요하다.
    - HTTP 헤더를 이용하여 이전 서버의 정보를 담기도 한다.

# STORY 04 캐시 서버를 이용한 서버의 부하 분산

## 1. 캐시 서버의 이용

- 서버의 부하를 분산시키기 위해 캐시 서버를 이용할 수 있다.
- 캐시 서버는 프록시 구조를 사용하여 데이터를 캐시에 저장한다.
  - 프록시는 웹 서버와 클라이언트 사이에서 웹 서버에 대한 액세스 동작을 중개하는 역할을 한다.

## 2. 캐시 서버는 갱신일로 콘텐츠를 관리한다

- 캐시 서버 사용 시 부하 분산 장치와 마찬가지로 웹 서버 대신 DNS 서버에 등록한다.
  - 캐시 서버에서 웹 서버로 전달 시 캐시 서버는 웹 서버의 클라이언트가 되어 재요청한다.
  - 즉, 소켓을 생성하고 웹 서버의 소켓에 접속하여 요청 메시지를 보낸다.
- 캐시 서버를 거치고 웹 서버로 전달될 경우 HTTP 요청 헤더에 `Via` 값이 포함될 수 있다.
  - Via 는 현재 웹 서버에 어느 서버를 거치고 도달했는지 주소가 적혀있다.
  - 반대로 응답 시 캐시 서버를 거치고 갈 경우 Via 헤더가 포함될 수 있다.
- 웹 서버가 분산되어 있을 경우 HTTP 요청 URI 를 보고 판단할 수 있다.
- 캐시 서버는 웹 서버에서 받은 응답 메시지의 정보와 받은 일시를 기록한다.
  - 이전에 요청한 정보가 있을 경우 `If-Modified-Since` 헤더에 응답받은 시간을 포함하여 요청한다.
  - 이전에 요청한 정보가 없을 경우 위의 헤더값을 포함하지 않는다.
  - 캐시 서버의 요청에 `If-Modified-Since` 헤더값이 없거나, 갱신일을 비교하여 값이 변경되었을 경우 웹 서버에 전달하여 변경된 정보를 응답받는다.
  - 갱신일을 비교하여 변경되지 않았을 경우 캐시 서버의 정보를 그대로 응답한다.

## 3. 프록시의 원점은 포워드 프록시이다

- 클라이언트 측에 캐시 서버를 관리하는 방법도 있다. (포워드 프록시)
- 목적은 서버측에 설치하는 캐시 서버와 같지만, 당시의 포워드 프록시는 방화벽 역할 또한 수행하였다.
  - 방화벽은 IP 와 포트 번호만을 기준으로 하기 때문에 상세한 조건을 처리할 수 없다.
  - 포워드 프록시에서 방화벽을 처리할 경우 위험한 사이트에 대한 접근을 제한할 수 있다.
- 포워드 프록시를 설정하면 URL 의 내용에 상관 없이 요청을 모두 포워드 프록시에게 전달한다.
  - 클라이언트를 구분하기 위해 해당 요청 URL 은 http 등의 프로토콜까지 포함한 주소를 기록한다.
  - GET http://www.lab.cyber.co.kr/sample3.htm HTTP /1.1

## 4. 포워드 프록시를 개량한 리버스 프록시

- 포워드 프록시의 경우 브라우저의 설정이 필요하기 때문에 문제가 발생한다.
  - 브라우저에 문제가 있을 경우 제대로 동작하지 않는다.
  - 불특정 다수의 클라이언트 설정을 조작하기 어렵다.
- 이를 보완하기 위해 서버측에서 프록시를 관리하는 리버스 프록시가 등장하였다.

## 5. 트랜스페어런트 프록시

- 포워드 프록시와 리버스 프록시의 좋은 점만 취하는 트랜스페어런트 프록시가 있다.
- 클라이언트와 웹 서버 경로 사이에 트랜스페어런트 프록시를 설치하여 중간에 가로챈다.
  - 패킷의 맨 앞에 있는 IP 헤더의 수신처 IP 주소를 보고 적절한 웹 서버를 판단한다.
  - 클라이언트와 서버 모두 프록시의 개념을 인지하지 않아도 된다.

## 5-2. 프록시 개념 차이

- 프록시 : 클라이언트와 웹 서버 사이에서 요청을 중개하는 것
- 포워드 프록시 : 클라이언트 측에서 관리하는 프록시 (캐시 서버 + 방화벽 역할)
- 리버스 프록시 : 서버 측에서 관리하는 프록시 (캐시 서버), DNS 서버에 등록하는 과정 필요
- 트랜스페어런트 프록시 : 클라이언트와 웹 서버 사이의 요청을 가로채는 프록시, DNS 서버 등록 불필요

# STORY 05 콘텐츠 배포 서비스

## 1. 콘텐츠 배포 서비스를 이용한 부하 분산

- 서버에서 캐시 서버를 관리하는 것과 클라이언트에서 캐시 서버를 관리하는 것은 각각의 장단점이 있다.
  - 서버에서 관리할 경우 웹 서버의 부하를 절감하지만 인터넷의 트래픽 자체를 절감하는 효과는 없다.
    - 외부에서 들어온 모든 트래픽은 캐시 서버를 거쳐간다.
  - 클라이언트에서 관리할 경우 인터넷의 트래픽을 절감하는 효과는 있지만 웹 서버에서 관여할 수 없다.
    - 관리의 주체가 클라이언트이다.
- 두 방법의 장점을 취하여, 클라이언트측의 프로바이더에 두는 방법이 고안되었다.
  - 웹 서버 운영자는 프로바이더와 계약하여 해당 캐시 서버에 관여할 수 있다.
- 중요한 프로바이더에만 캐시 서버를 두어 클라이언트 측의 캐시 서버 수를 줄인다.
  - 모든 클라이언트에 캐시 서버를 두기에는 부담이 된다.
  - 일부 프로바이더를 무조건 거쳐가야 해서 우회하여 도달할 수 있지만 웹 서버까지의 거리보다는 가깝다.
- 이러한 캐시 서버를 관리할 수 있도록 제공하는 사업을 ‘콘텐츠 배포 서비스’ 라고 한다.

## 2. 가장 가까운 캐시 서버의 관점

- 효율적으로 제공하기 위해 다수의 캐시 서버를 두어 가장 가까운 캐시 서버를 거쳐간다.
- 클라이언트에서 웹 서버로의 접근이 아닌 캐시 서버로 접근하기 위해 DNS 서버에 캐시 서버의 IP 를 등록한다.
- 클라이언트에서 DNS 서버에 접근 시 가장 가까운 캐시 서버의 IP 주소를 반환한다.
  - DNS 서버는 캐시 서버들의 라우터 경로 테이블 정보를 입수한다.
  - 라우팅 테이블을 이용하여 캐시 서버에서 DNS 서버까지의 경로가 가장 짧은 서버의 정보를 찾는다.

## 3. 리피터용 서버로 액세스 대상을 분배한다

- 가장 가까운 캐시 서버를 찾는 역할을 DNS 서버가 아닌 리다이렉트용 웹 서버를 별도로 설치하여 활용할 수 있다.
- DNS 서버에는 리다이렉트용 웹 서버의 주소를 등록한다.
- 리다이렉트용 웹 서버는 이전의 DNS 서버처럼 캐시 서버들의 라우팅 테이블을 입수하고 가장 가까운 캐시 서버의 IP 주소를 반환한다.
- IP 주소 반환 시 HTTP 응답 메시지를 302의 Location 헤더 필드를 사용할 수도 있다.

## 4. 캐시 내용의 갱신 방법에서 성능의 차이가 난다

- 캐시 서버의 데이터를 최신 데이터로 관리하기 위해 웹 서버에서 데이터의 변경이 있을 경우 이를 즉시 캐시 서버에 적용해야 한다.
